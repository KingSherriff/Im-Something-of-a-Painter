{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iâ€™m Something of a Painter Myself - Image Generation\n",
    "## Introduction\n",
    "Our goal in this project is to create a Generative Adversarial Network (GAN), which consists of a Generator model and a Deiscriminator model, that can somewhat accurately generate images in the Monet art style. Our GAN must generate between 7,000 and 10,000 Money-style images and will be evaluated on MiFID. Our dataset should consist 300 monet jpg's, 7038 photo jpg's, 5 monet tfrec files, and 30 photo tfrec files. For our solution we will be focusing primarily on the monet jpg files as our goal is to generate entirely new photos in the monet art style. With this in mind we should note that our monet jpgs should be sized 256 by 256, RGB, and in the JPEG format (effectively of a shape (256, 256, 3)) but we will proceed with data analysis to confirm this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:21.393070Z",
     "iopub.status.busy": "2025-12-08T22:14:21.392507Z",
     "iopub.status.idle": "2025-12-08T22:14:21.397181Z",
     "shell.execute_reply": "2025-12-08T22:14:21.396460Z",
     "shell.execute_reply.started": "2025-12-08T22:14:21.393017Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a2f2e112c8c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# =============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0m_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilence_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_conv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_converters\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5t.pxd\u001b[0m in \u001b[0;36minit h5py._conv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5t.pyx\u001b[0m in \u001b[0;36minit h5py.h5t\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[0;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, ReLU, Flatten, Dense, Dropout, BatchNormalization, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:21.443937Z",
     "iopub.status.busy": "2025-12-08T22:14:21.443397Z",
     "iopub.status.idle": "2025-12-08T22:14:21.482674Z",
     "shell.execute_reply": "2025-12-08T22:14:21.482169Z",
     "shell.execute_reply.started": "2025-12-08T22:14:21.443918Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dir = \"/kaggle/input/gan-getting-started/monet_jpg\"\n",
    "real_monet = keras.utils.image_dataset_from_directory(img_dir, label_mode=None, image_size = (256, 256), batch_size = 32)\n",
    "real_monet = real_monet.map(lambda x: (x / 127.5) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "As we will be focused primarily on image generation in the monet style we are making use of only the monet jpg data. Analysing this shows us some much expected and some interesting results. As expected we have 300 images all of 256 by 256 size on an RGB scale. Below we will display some sample images to get an idea for what a 'monet' image really is and we can see how it uses a distinct painting like art style of primarily scenery and objects such as flowers. Taking a deeper look at the image data we can see that our transformation of the color values from the 0 to 255 range down to the -1 to 1 range has taken affect and that there is often a lot of overlap in pixel intensity per color per image. While there are of course exceptions where some images contain significantly more of one or two colors over another we can see that this is usually not the case by observing the color intensity of all our monet images. As shown most images result in an accumulated overlap in pixel intensity with the exception of some images containing absolutely no blue and some but fewer containing no red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:21.494411Z",
     "iopub.status.busy": "2025-12-08T22:14:21.493756Z",
     "iopub.status.idle": "2025-12-08T22:14:26.584672Z",
     "shell.execute_reply": "2025-12-08T22:14:26.583822Z",
     "shell.execute_reply.started": "2025-12-08T22:14:21.494394Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_sample_images():\n",
    "    batch = next(iter(real_monet))\n",
    "    display_images = batch[:16]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.suptitle(\"Sample Monet Images\")\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((display_images[i]))\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_image_size():\n",
    "    sizes = [Image.open(os.path.join(img_dir, file)).size for file in os.listdir(img_dir)]\n",
    "    widths, heights = zip(*sizes)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title(\"Image Width Distribution\")\n",
    "    plt.xlabel(\"Width\")\n",
    "    plt.ylabel(\"Image Count\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(heights, bins=20, color='salmon', edgecolor='black')\n",
    "    plt.title(\"Image Height Distribution\")\n",
    "    plt.xlabel(\"Height\")\n",
    "    plt.ylabel(\"Image Count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show\n",
    "\n",
    "def analyze_image_colors():\n",
    "    batch = next(iter(real_monet))\n",
    "    display_images = batch[:16]\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    for i, color in enumerate(colors):\n",
    "        plt.hist(display_images[0].numpy()[:, :, i].ravel(), bins=256, alpha=0.5, color=color)\n",
    "\n",
    "    plt.title('RGB Histogram of a Random Image')\n",
    "    plt.xlabel('Pixel value')\n",
    "    plt.ylabel('Pixel Count')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    pixels_values = [[], [], []]\n",
    "\n",
    "    for i in range(len(pixels_values)):\n",
    "        for batch in real_monet:\n",
    "            batch_np = batch.numpy()\n",
    "            pixels_values[i].append(batch_np[:, :, :, i].ravel())\n",
    "    pixels_values = [np.concatenate(color) for color in pixels_values]\n",
    "\n",
    "    plt.hist(pixels_values[0], bins=256, color='red', alpha=0.5, label='Red')\n",
    "    plt.hist(pixels_values[1], bins=256, color='green', alpha=0.5, label='Green')\n",
    "    plt.hist(pixels_values[2], bins=256, color='blue', alpha=0.5, label='Blue')\n",
    "    plt.title(\"RGB Histogram On All Images\")\n",
    "    plt.xlabel(\"Pixel value\")\n",
    "    plt.ylabel(\"Pixel count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show\n",
    "\n",
    "display_sample_images()\n",
    "analyze_image_size()\n",
    "analyze_image_colors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "After much research I am going with a DCGAN due to it's stated stability when compared to other models and it's usefulness in images of around the same quality of 256 by 256 pictuures. A number of architectures were considered for this project before I finally settled on the DCGAN. The architecture I was most excited for was the Progressive GAN. This architecture allows us to start off at a much lower resolution such as 4 by 4 and progressively upscale so that our generator can produce high quality images. However it quickly became apperant that this method would be far too computationally expensive and may not provide significant benefit for our images that are only 256 by 256. Models like mDCGAN were attractive as they appeared to be targeting this specific problem, however the paper shows that there is still much work to be done regarding their overfitting and instability: https://arxiv.org/pdf/2403.18397. Because of this it appeared clear that I was best off sticking with a simple but powerful GAN that would be effective, stable, and relatively quick which was the DCGAN. While the quality of the final result may not be perfect, it appears most worth the cost and most stable option available.\n",
    "\n",
    "### DCGAN/LSGAN\n",
    "DCGAN's are a well established and popular convolution GAN architecture that are known for their relative stability and efficient training when compared with more specialized architectures especially for moderate resolutions like ours. It avoids using fully connected layers and max pooling to instead use convolutional and transposed-convolutional layers alongside batch normalization to stabilize its learning ability by downsampling and upsampling. Advancements in mode architecture have shown even further efficiencies can be gained by using LeakyReLU in the discriminator. While the model architecture itself will remain exactly the same, it must be acknowledged that we will also be testing the Least Squared Loss method and this is at times considered it's own architecture. For this project, because we will not be adjusting the model approach other than the loss and this approach is largely associated with DCGAN I will largely refer to the architecture as DCGAN and one of the loss functions as Least Squared Loss.\n",
    "\n",
    "### Minimax Loss\n",
    "I will be making use of the original loss function proposed in the GAN paper in order to get a baseline and an understanding of the model especially in comparison to the two loss functions we will test later on. This loss function has the discriminator attempt to maximize loss while the generator attempts to minimize it and is the original foundation of GAN trainig.\n",
    "\n",
    "### Modified Minimax Loss\n",
    "This is a loss function generally known to outperform Minimax loss by resolving one of the primary issues that existed in the old function. The discriminator has a very easy time identifying fake images early on in original formula which can result in the generator not learning as it's attempts at improvement are overwhelmed by the discriminator's ability to identify fake images. To resolve this issue the generator attemptes to maximize the log of the loss rather than minimize the loss itself.\n",
    "\n",
    "### Least Square Loss\n",
    "I'll be using Least Square Loss as well and comparing the results with the Modified Minimax Loss. The idea behind the Least Squared Loss appears to be that often the discrinimator is quite good at identifying fake images, but not very helpful in training the generator. This is quite similar to the issue that Modified Minimax Loss resolved. The difference is in how Least Squared Loss calculates more linear gradients than the Modified Minimax method which can have very small or very large gradients further resulting in very small or very large swings. The idea would be that Least Squared Loss should result in a smoother gradient and thus more refined training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:26.586341Z",
     "iopub.status.busy": "2025-12-08T22:14:26.586083Z",
     "iopub.status.idle": "2025-12-08T22:14:26.592459Z",
     "shell.execute_reply": "2025-12-08T22:14:26.591801Z",
     "shell.execute_reply.started": "2025-12-08T22:14:26.586322Z"
    }
   },
   "outputs": [],
   "source": [
    "class GANDiscriminator:\n",
    "    def __init__(self, input_shape=(256, 256, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        discriminator = keras.Sequential()\n",
    "        discriminator.add(keras.Input(shape = self.input_shape))\n",
    "        discriminator.add(Conv2D(64, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Conv2D(128, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Conv2D(256, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Conv2D(512, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Flatten())\n",
    "        discriminator.add(Dropout(0.2))\n",
    "        discriminator.add(Dense(1, activation = 'sigmoid'))\n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:26.593454Z",
     "iopub.status.busy": "2025-12-08T22:14:26.593263Z",
     "iopub.status.idle": "2025-12-08T22:14:26.607712Z",
     "shell.execute_reply": "2025-12-08T22:14:26.607111Z",
     "shell.execute_reply.started": "2025-12-08T22:14:26.593431Z"
    }
   },
   "outputs": [],
   "source": [
    "class GANDiscriminatorLS:\n",
    "    def __init__(self, input_shape=(256, 256, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        discriminator = keras.Sequential()\n",
    "        discriminator.add(keras.Input(shape = self.input_shape))\n",
    "        discriminator.add(Conv2D(64, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Conv2D(128, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Conv2D(256, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Conv2D(512, 4, 2, 'same'))\n",
    "        discriminator.add(LeakyReLU(0.2))\n",
    "        discriminator.add(Flatten())\n",
    "        discriminator.add(Dropout(0.2))\n",
    "        discriminator.add(Dense(1))\n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:26.609420Z",
     "iopub.status.busy": "2025-12-08T22:14:26.609208Z",
     "iopub.status.idle": "2025-12-08T22:14:26.620390Z",
     "shell.execute_reply": "2025-12-08T22:14:26.619684Z",
     "shell.execute_reply.started": "2025-12-08T22:14:26.609404Z"
    }
   },
   "outputs": [],
   "source": [
    "class GANGenerator:\n",
    "    def __init__(self, input_shape=(128,)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        generator = keras.Sequential()\n",
    "        generator.add(Dense(4 * 4 * 1024))\n",
    "        generator.add(Reshape((4, 4, 1024)))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(ReLU())\n",
    "        \n",
    "        generator.add(Conv2DTranspose(512, 4, 2, 'same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(ReLU())\n",
    "        \n",
    "        generator.add(Conv2DTranspose(256, 4, 2, 'same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(ReLU())\n",
    "        \n",
    "        generator.add(Conv2DTranspose(128, 4, 2, 'same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(ReLU())\n",
    "\n",
    "        generator.add(Conv2DTranspose(64, 4, 2, 'same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(ReLU())\n",
    "\n",
    "        generator.add(Conv2DTranspose(32, 4, 2, 'same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(ReLU())\n",
    "        \n",
    "        generator.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh'))\n",
    "        return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:26.621292Z",
     "iopub.status.busy": "2025-12-08T22:14:26.621090Z",
     "iopub.status.idle": "2025-12-08T22:14:26.634072Z",
     "shell.execute_reply": "2025-12-08T22:14:26.633520Z",
     "shell.execute_reply.started": "2025-12-08T22:14:26.621277Z"
    }
   },
   "outputs": [],
   "source": [
    "class Minimax:\n",
    "    def d_loss(self, real, fake):\n",
    "        return -(tf.reduce_mean(tf.math.log(real + 1e-8)) + tf.reduce_mean(tf.math.log(1 - fake + 1e-8)))\n",
    "    \n",
    "    def g_loss(self, fake):\n",
    "        return tf.reduce_mean(tf.math.log(1 - fake + 1e-8))\n",
    "\n",
    "class ModifiedMinimax:\n",
    "    def d_loss(self, real, fake):\n",
    "        return -(tf.reduce_mean(tf.math.log(real + 1e-8)) + tf.reduce_mean(tf.math.log(1 - fake + 1e-8)))\n",
    "    \n",
    "    def g_loss(self, fake):\n",
    "        return -tf.reduce_mean(tf.math.log(fake + 1e-8))\n",
    "\n",
    "class LeastSquare:\n",
    "    def d_loss(self, real, fake):\n",
    "        return 0.5 * (tf.reduce_mean((real - 1 + 1e-8) ** 2)) + 0.5 * (tf.reduce_mean(fake ** 2))\n",
    "    \n",
    "    def g_loss(self, fake):\n",
    "        return tf.reduce_mean((fake - 1 + 1e-8) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:26.634936Z",
     "iopub.status.busy": "2025-12-08T22:14:26.634683Z",
     "iopub.status.idle": "2025-12-08T22:14:26.645830Z",
     "shell.execute_reply": "2025-12-08T22:14:26.645316Z",
     "shell.execute_reply.started": "2025-12-08T22:14:26.634912Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, generator, discriminator, loss):\n",
    "        self.generator = generator.model\n",
    "        self.discriminator = discriminator.model\n",
    "        self.loss = loss\n",
    "        self.latent_dim = generator.input_shape[0]\n",
    "        self.g_optimizer = Adam(0.0002, 0.5)\n",
    "        self.d_optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    def generate_and_save_images(self, epoch):\n",
    "        noise = tf.random.normal([16, self.latent_dim])\n",
    "        predictions = self.generator(noise, training=False)\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        \n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(tf.clip_by_value((predictions[i] + 1) / 2, 0, 255))\n",
    "            plt.axis('off')\n",
    "        \n",
    "        # plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "        plt.show()\n",
    "\n",
    "    def train(self, dataset, epochs=20):\n",
    "        for epoch in range(epochs):\n",
    "            for real_images in dataset:\n",
    "                batch_size = tf.shape(real_images)[0]\n",
    "                noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "                \n",
    "                with tf.GradientTape() as d_tape:\n",
    "                    fake_images = self.generator(noise, training=True)\n",
    "                    real_out = self.discriminator(real_images, training=True)\n",
    "                    fake_out = self.discriminator(fake_images, training=True)\n",
    "                    d_loss = self.loss.d_loss(real_out, fake_out)\n",
    "                \n",
    "                d_gradiants = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "                self.d_optimizer.apply_gradients(zip(d_gradiants, self.discriminator.trainable_variables))\n",
    "                \n",
    "                with tf.GradientTape() as g_tape:\n",
    "                    fake_images = self.generator(noise, training=True)\n",
    "                    fake_out = self.discriminator(fake_images, training=True)\n",
    "                    g_loss = self.loss.g_loss(fake_out)\n",
    "                \n",
    "                g_gradiants = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "                self.g_optimizer.apply_gradients(zip(g_gradiants, self.generator.trainable_variables))\n",
    "            \n",
    "            print(f\"Epoch {epoch}: D={d_loss}, G={g_loss}\")\n",
    "        self.generate_and_save_images(epoch)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:14:26.646616Z",
     "iopub.status.busy": "2025-12-08T22:14:26.646460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D=0.0014032423496246338, G=-0.0008827616111375391\n",
      "Epoch 1: D=0.0003164796798955649, G=-0.0002800225920509547\n",
      "Epoch 2: D=0.0002098709373967722, G=-0.00016371917445212603\n",
      "Epoch 3: D=0.00013362415484152734, G=-0.00011243185872444883\n",
      "Epoch 4: D=9.59680910455063e-05, G=-7.950617145979777e-05\n",
      "Epoch 5: D=9.420041897101328e-05, G=-7.451431156368926e-05\n",
      "Epoch 6: D=6.100285463617183e-05, G=-5.477397280628793e-05\n",
      "Epoch 7: D=0.00012079489533789456, G=-4.725799590232782e-05\n",
      "Epoch 8: D=4.0745926526142284e-05, G=-3.656341141322628e-05\n",
      "Epoch 9: D=2.8595806725206785e-05, G=-2.7398707970860414e-05\n",
      "Epoch 10: D=2.385709376540035e-05, G=-2.1875195670872927e-05\n",
      "Epoch 11: D=8.602638263255358e-05, G=-1.9481014533084817e-05\n",
      "Epoch 12: D=1.9431387045187876e-05, G=-1.8482651285012253e-05\n",
      "Epoch 13: D=1.7156420653918758e-05, G=-1.5730844097561203e-05\n",
      "Epoch 14: D=1.5447740224772133e-05, G=-1.5244118003465701e-05\n",
      "Epoch 15: D=1.4434438526222948e-05, G=-1.3341672456590459e-05\n",
      "Epoch 16: D=1.703239104244858e-05, G=-1.5909807189018466e-05\n",
      "Epoch 17: D=9.680861694505438e-06, G=-9.581523045198992e-06\n",
      "Epoch 18: D=9.089768354897387e-06, G=-8.876188985595945e-06\n",
      "Epoch 19: D=9.959029739547987e-06, G=-9.661001968197525e-06\n",
      "Epoch 20: D=4.1949479054892436e-05, G=-6.298249445535475e-06\n",
      "Epoch 21: D=2.5044913854799233e-05, G=-1.4678095794806723e-05\n"
     ]
    }
   ],
   "source": [
    "# mmgan = GAN(GANGenerator(), GANDiscriminator(), Minimax()).train(real_monet, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modmmgan = GAN(GANGenerator(), GANDiscriminator(), ModifiedMinimax()).train(real_monet, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsgan = GAN(GANGenerator(), GANDiscriminatorLS(), LeastSquare()).train(real_monet, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results, Analysis, and Discussion\n",
    "Our baseline model of DCGAN + Minimax initially performs well but quickly exhibits catastrophic failures after around 10 - 20 training sessions as can be seen above and below. Having observed this model for some time it is apperant that the discriminator has become too powerful and can simply refuse any image that the generator suggests. Because of this there is no opportunity for the generator to train and thus it remains stuck. Manipulating the hyperparameters of the model in order to weaken the discriminator was at times successful, however it quickly became clear that a more robust manipulation method would be required as the discriminator and generator would still fly to various extremes. From this I have clearly learned why loss functions like the Modified Minimax were such significant advancements.\n",
    "\n",
    "It was with our DCGAN + Modified Minimax that I began seeing success in the models' competition and image output. With this loss function more epochs are a clear benefit and the model no longer got stuck with the discriminator not allowing the generator to train. Managing the hyperparameters of this combination did not consistantly produce better results as it was found maintaining a relatively equal learning rate resulted in the most competition and stability while decreasing or increasing the learning rate of the discriminator from the generator saw less stable results.\n",
    "\n",
    "It was interesting to note that the DCGAN (Sigmoid) + Least Squared combination would consistantly result in issues similar to the DCGAN + Minimax combination. The discriminator would at times overpower the generator, but it was also possible for the generator to create an image that simply confused the discriminator so much it defaulted to guessing. It was not until the Sigmoid was removed from the end of the discriminator that the Least Squared loss function began to really function.\n",
    "\n",
    "The DCGAN (No Sigmoid) + Least Squared combination showed about as high quality images as the DCGAN + Modified Minimax with different issues. While the DCGAN Modified Minimax consistantly retains textures after 150 epochs, the DCGAN (No Sigmoid) + Least Squared has less obvious textures and uses more accurate colors but cannot shape the image. I would imagine that with more epochs or training data that DCGANLS would quickly outpace the DCGANMM and this would be an interesting project to persue on future research.\n",
    "\n",
    "### Troubleshooting\n",
    "While the Sigmoid issue in DCGAN + Least Squared loss was frustrating, that was more a matter of architecture building than troubleshooting. An example of troubleshooting for this project would instead be adding a tiny value to the loss functions of Minimax and Modified Minimax such that they avoided immediately failing to compete with each other. While this did extend the length of competition for the Minimax from 5 - 10 epochs to 10 - 20, it did not resolve the problem. This did help the Modified Minimax for the rare occasions it would get stuck however.\n",
    "\n",
    "### Hyperparameter Optimization\n",
    "I found it was much better to keep learning rate relatively equal between generator and discriminator and that increasing both too much would result in less stable results. The reasons for this are described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmgan.generate_and_save_images(20)\n",
    "# modmmgan.generate_and_save_images(20)\n",
    "# lsgan.generate_and_save_images(20)\n",
    "\n",
    "# D_loss = [\n",
    "#     0.00030226021772250533, 0.0001632011408219114, 0.001095915911719203,\n",
    "#     0.00014471187023445964, 0.00010964041575789452, 0.00018400012049824,\n",
    "#     9.86422601272352e-05, 0.0002167695201933384, 0.00027913370286114514,\n",
    "#     9.911440429277718e-05, 0.000533958082087338, 4.5649405365111306e-05,\n",
    "#     0.0037470886018127203, 18.420724868774414, 18.42069435119629,\n",
    "#     18.42068099975586, 18.420743942260742, 18.420684814453125,\n",
    "#     18.420696258544922, 18.420686721801758, 18.420682907104492,\n",
    "#     18.42068099975586, 18.420684814453125, 18.420799255371094,\n",
    "#     18.420785903930664, 18.420682907104492, 18.42068099975586,\n",
    "#     18.420682907104492, 18.420682907104492, 18.42068099975586,\n",
    "#     18.42068099975586, 18.42068099975586, 18.420774459838867,\n",
    "#     18.42068099975586, 18.42068099975586, 18.42068099975586,\n",
    "#     18.420682907104492, 18.4207706451416, 18.42068099975586,\n",
    "#     18.420682907104492, 18.420740127563477, 18.42068099975586,\n",
    "#     18.42068099975586, 18.42069435119629, 18.42068099975586,\n",
    "#     18.420682907104492, 18.42069435119629, 18.42068099975586,\n",
    "#     18.42069435119629, 18.420711517333984, 18.42068099975586,\n",
    "#     18.420732498168945, 18.42068099975586, 18.42068099975586,\n",
    "#     18.420692443847656, 18.42068099975586, 18.42068099975586,\n",
    "#     18.42068099975586, 18.420686721801758, 18.42068099975586,\n",
    "#     18.42068862915039, 18.420705795288086, 18.42068099975586,\n",
    "#     18.42068099975586, 18.42068099975586, 18.42068099975586,\n",
    "#     18.42068099975586, 18.42068862915039, 18.42068099975586,\n",
    "#     18.42068099975586, 18.42068099975586, 18.42068099975586,\n",
    "#     18.42068099975586, 18.42068099975586, 18.42068099975586\n",
    "# ]\n",
    "\n",
    "# G_loss = [\n",
    "#     -0.00018513838585931808, -0.00013681814016308635, -0.0001428105606464669,\n",
    "#     -0.00012721147504635155, -9.721130481921136e-05, -9.414148371433839e-05,\n",
    "#     -8.242313197115436e-05, -8.242439798777923e-05, -7.940903014969081e-05,\n",
    "#     -6.882729212520644e-05, -0.00016810104716569185, -3.4701082768151537e-05,\n",
    "#     -1.7111870050430298, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586, -18.42068099975586,\n",
    "#     -18.42068099975586, -18.42068099975586\n",
    "# ]\n",
    "\n",
    "# epochs = range(len(D_loss))\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(epochs, D_loss, label='Discriminator Loss', color='red')\n",
    "# plt.plot(epochs, G_loss, label='Generator Loss', color='blue')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('GAN Minimax Loss Comparison Over Epochs')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# D_loss = [\n",
    "# 0.05907316505908966,0.765148401260376,0.32629328966140747,2.0534491539001465,0.12806583940982819,\n",
    "# 1.7434107065200806,0.8857859969139099,0.21490097045898438,0.21478474140167236,0.9253175854682922,\n",
    "# 0.26750659942626953,0.3260268270969391,0.44012966752052307,0.46202749013900757,1.1371620893478394,\n",
    "# 0.7010257244110107,0.8140944242477417,0.9412343502044678,0.8418732285499573,0.8325721025466919,\n",
    "# 0.7507286667823792,0.485018789768219,0.8254764676094055,0.4930475354194641,1.667496681213379,\n",
    "# 0.5925298929214478,0.5080060362815857,0.9833872318267822,0.8390513062477112,1.020677924156189,\n",
    "# 0.9010607004165649,0.8495804071426392,0.8114984631538391,0.7028030157089233,1.2650383710861206,\n",
    "# 0.56020188331604,0.5441453456878662,4.5557403564453125,0.8735983967781067,1.2475690841674805,\n",
    "# 0.46465396881103516,0.32156044244766235,1.209265947341919,2.765371322631836,0.7090467810630798,\n",
    "# 0.7065113186836243,0.6886517405509949,0.8031829595565796,0.4930500090122223,0.7590029239654541,\n",
    "# 0.6448805928230286,0.7679719924926758,0.39529043436050415,0.6636484861373901,1.163271188735962,\n",
    "# 0.8335174322128296,0.8263005018234253,2.4323110580444336,0.4896933436393738,0.7408528327941895,\n",
    "# 1.349420428276062,0.5672570466995239,0.4981870949268341,1.0666217803955078,0.43215376138687134,\n",
    "# 0.7394095063209534,1.0439600944519043,1.0271629095077515,0.34197166562080383,0.36713024973869324,\n",
    "# 0.8801013231277466,0.5869637131690979,0.24425697326660156,0.3955335319042206,1.356328010559082,\n",
    "# 0.46260374784469604,0.207957923412323,0.5909383296966553,0.34905627369880676,0.5348270535469055,\n",
    "# 0.8589470386505127,0.6342974305152893,0.6218961477279663,0.9074400067329407,1.5008602142333984,\n",
    "# 0.7488741278648376,0.3388282060623169,0.29697757959365845,2.3153483867645264,0.34926432371139526,\n",
    "# 0.5087008476257324,1.9939391613006592,2.4954311847686768,0.4893020987510681,0.31429362297058105,\n",
    "# 0.36408019065856934,0.6666197180747986,0.6343185305595398,0.5447461605072021,0.5116433501243591,\n",
    "# 0.4101419746875763,0.976739227771759,0.6453350782394409,0.4812643229961395,0.6596757769584656,\n",
    "# 0.3660552203655243,1.165662169456482,0.37033721804618835,0.6336507201194763,0.9154776334762573,\n",
    "# 0.6905319690704346,1.0782923698425293,0.31939733028411865,2.6272785663604736,2.292400598526001,\n",
    "# 0.7808389067649841,1.3600236177444458,1.0810743570327759,1.2127851247787476,0.66426020860672,\n",
    "# 0.43389737606048584,0.7675861120223999,0.3942677974700928,0.6988362669944763,0.6154128313064575,\n",
    "# 0.5166749954223633,0.801056444644928,1.0678097009658813,0.8563038110733032,0.680034875869751,\n",
    "# 0.25236615538597107,1.1124693155288696,0.4434988498687744,0.47096920013427734,0.5418143272399902,\n",
    "# 1.0645931959152222,0.3889177143573761,0.22909750044345856,0.3869989514350891,0.7674368619918823,\n",
    "# 0.8758338689804077,0.5152714252471924,0.9088233113288879,0.6711258888244629,0.6930534839630127,\n",
    "# 0.47391581535339355,1.6606000661849976,0.4120970368385315,0.48241710662841797,0.2887883484363556\n",
    "# ]\n",
    "\n",
    "# G_loss = [\n",
    "# 9.922026634216309,16.434288024902344,2.5734164714813232,10.564234733581543,3.4854869842529297,\n",
    "# 5.861950397491455,2.508126974105835,4.19541597366333,3.311798334121704,5.723763942718506,\n",
    "# 3.3001339435577393,3.4893853664398193,2.7312355041503906,2.096461534500122,2.051333427429199,\n",
    "# 1.5378079414367676,1.8389643430709839,3.810523748397827,1.4378210306167603,1.6168843507766724,\n",
    "# 1.6731992959976196,2.293137788772583,4.602846145629883,1.9022337198257446,6.282419681549072,\n",
    "# 1.776357650756836,1.9683071374893188,1.2933415174484253,2.0634117126464844,1.1907470226287842,\n",
    "# 2.916842460632324,3.1728675365448,1.940657615661621,1.8730119466781616,2.4316887855529785,\n",
    "# 2.131993293762207,2.64784836769104,2.6562163829803467,1.8550214767456055,3.0282504558563232,\n",
    "# 2.506181001663208,2.8914756774902344,3.865903854370117,5.0046257972717285,2.4862048625946045,\n",
    "# 2.154369592666626,3.1476383209228516,2.2084267139434814,2.401252508163452,3.095590829849243,\n",
    "# 2.563833236694336,4.725097179412842,2.42763352394104,2.1184589862823486,4.958104610443115,\n",
    "# 2.3080646991729736,2.0389816761016846,5.79784631729126,1.8139311075210571,3.726696014404297,\n",
    "# 2.55903959274292,3.185354232788086,4.057209014892578,3.3358185291290283,2.838630437850952,\n",
    "# 2.2831642627716064,4.27665901184082,2.850531816482544,4.082967281341553,3.888246774673462,\n",
    "# 4.77682638168335,2.842278242111206,3.007739305496216,3.2956628799438477,3.2881228923797607,\n",
    "# 2.9683284759521484,2.502959966659546,3.4810807704925537,2.123448133468628,2.4035990238189697,\n",
    "# 1.1339141130447388,2.4287967681884766,2.2000808715820312,5.259675025939941,5.190953731536865,\n",
    "# 3.9986279010772705,2.291086196899414,5.546712398529053,2.192201852798462,2.6106832027435303,\n",
    "# 2.662893056869507,3.3034420013427734,3.032949209213257,2.1940832138061523,3.2679460048675537,\n",
    "# 2.9496958255767822,3.143054962158203,2.019531488418579,3.505791425704956,3.383262872695923,\n",
    "# 2.181205987930298,3.280266523361206,2.404890298843384,4.04025411605835,3.1851541996002197,\n",
    "# 2.927860975265503,3.6697542667388916,3.762620210647583,3.9697721004486084,2.0809197425842285,\n",
    "# 3.253615379333496,1.8960891962051392,2.72040057182312,5.764845371246338,5.682908535003662,\n",
    "# 3.692528009414673,2.820180892944336,8.39954948425293,5.618049144744873,1.7350502014160156,\n",
    "# 2.1004064083099365,4.515822887420654,3.582066535949707,6.067647457122803,3.3199920654296875,\n",
    "# 4.068695545196533,2.1540749073028564,2.75537109375,4.568722724914551,4.268860340118408,4.014780521392822,\n",
    "# 2.5353071689605713,4.351078033447266,2.846605062484741,5.19195032119751,3.6394312381744385,\n",
    "# 3.5950710773468018,3.147618055343628,3.0181896686553955,3.593151092529297,1.844223976135254,\n",
    "# 2.5540387630462646,2.8724403381347656,3.3817617893218994,1.650761604309082,2.6266698837280273,\n",
    "# 9.222198486328125,2.867569923400879,3.7920703887939453,5.1172051429748535\n",
    "# ]\n",
    "\n",
    "# epochs = range(len(D_loss))\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(epochs, D_loss, label='Discriminator Loss', color='red')\n",
    "# plt.plot(epochs, G_loss, label='Generator Loss', color='blue')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('GAN Modified Minimax Loss Comparison Over Epochs')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# D_loss = [\n",
    "#     0.1451229751110077, 0.029422640800476074, 0.026898125186562538,\n",
    "#     0.22019483149051666, 0.041806671768426895, 0.25858160853385925,\n",
    "#     0.060392364859580994, 0.10296380519866943, 0.10640434175729752,\n",
    "#     0.07269785553216934, 0.06568615138530731, 0.15339289605617523,\n",
    "#     0.06135626137256622, 0.056728631258010864, 0.04950175806879997,\n",
    "#     0.2897239327430725, 0.1471877247095108, 0.06674494594335556,\n",
    "#     0.0886010155081749, 0.06297273188829422, 0.0667300671339035,\n",
    "#     0.13401898741722107, 0.07189113646745682, 0.14177411794662476,\n",
    "#     0.0618315264582634, 0.10892052948474884, 0.11042412370443344,\n",
    "#     0.06322507560253143, 0.11871757358312607, 0.06282610446214676,\n",
    "#     0.24067604541778564, 0.08043062686920166, 0.07285833358764648,\n",
    "#     0.09888337552547455, 0.13188770413398743, 0.07803692668676376,\n",
    "#     0.25564703345298767, 0.07585036009550095, 0.03477597236633301,\n",
    "#     0.08187875896692276, 0.15293948352336884, 0.05809887871146202,\n",
    "#     0.059734150767326355, 0.0516970120370388, 0.0936778113245964,\n",
    "#     0.07748164981603622, 0.1467682123184204, 0.059696100652217865,\n",
    "#     0.05000869557261467, 0.06700508296489716, 0.042190708220005035,\n",
    "#     0.08539193123579025, 0.06903672218322754, 0.2239503711462021,\n",
    "#     0.062361136078834534, 0.0715961754322052, 0.08512159436941147,\n",
    "#     0.050334177911281586, 0.035908278077840805, 0.03759823739528656,\n",
    "#     0.073418028652668, 0.04303625971078873, 0.05194612964987755,\n",
    "#     0.06259707361459732, 0.06969702243804932, 0.08983666449785233,\n",
    "#     0.05427679046988487, 0.09425187110900879, 0.09856470674276352,\n",
    "#     0.04298315942287445, 0.07976757735013962, 0.049986258149147034,\n",
    "#     0.2903621792793274, 0.05186131224036217, 0.0770365446805954,\n",
    "#     0.08250115066766739, 0.06649129837751389, 0.14190521836280823,\n",
    "#     0.03248662129044533, 0.0980394259095192, 0.06673751771450043,\n",
    "#     0.07071943581104279, 0.16942906379699707, 0.03616825491189957,\n",
    "#     0.045327868312597275, 0.24671345949172974, 0.06486133486032486,\n",
    "#     0.25694262981414795, 0.06209216266870499, 0.11847265064716339,\n",
    "#     0.10632042586803436, 0.06526167690753937, 0.0161538477987051,\n",
    "#     0.06393645703792572, 0.07535409182310104, 0.06175953894853592,\n",
    "#     0.04804546386003494, 0.17045515775680542, 0.06089963763952255,\n",
    "#     0.08905008435249329, 0.16137811541557312, 0.05547340214252472,\n",
    "#     0.0720883384346962, 0.06113136559724808, 0.060258638113737106,\n",
    "#     0.06842871755361557, 0.06741984933614731, 0.1078934594988823,\n",
    "#     0.09868447482585907, 0.09710857272148132, 0.0636286810040474,\n",
    "#     0.10165742039680481, 0.0536704882979393, 0.11985445767641068,\n",
    "#     0.15044282376766205, 0.14116819202899933, 0.0614730566740036,\n",
    "#     0.09086740016937256, 0.38104739785194397, 0.0535072460770607,\n",
    "#     0.11450734734535217, 0.08803485333919525, 0.042416367679834366,\n",
    "#     0.1650751829147339, 0.07678847014904022, 0.09064720571041107,\n",
    "#     0.1529608517885208, 0.038187868893146515, 0.0893968939781189,\n",
    "#     0.27196842432022095, 0.1185372918844223, 0.06591559946537018,\n",
    "#     0.08229487389326096, 0.09221340715885162, 0.10962092876434326,\n",
    "#     0.06251218914985657, 0.05588366836309433, 0.12703990936279297,\n",
    "#     0.117399662733078, 0.10101692378520966, 0.2983015477657318,\n",
    "#     0.12179946899414062, 0.11301297694444656, 0.05110534280538559,\n",
    "#     0.06649987399578094, 0.21419765055179596, 0.06907571107149124,\n",
    "#     0.07582459598779678, 0.0469534806907177, 0.1096627339720726\n",
    "# ]\n",
    "\n",
    "# G_loss = [\n",
    "#     0.8010559678077698, 1.3058394193649292, 1.0737227201461792,\n",
    "#     0.880169153213501, 1.2058944702148438, 0.23591482639312744,\n",
    "#     1.076488733291626, 1.2368606328964233, 1.218985915184021,\n",
    "#     0.946252167224884, 1.9792193174362183, 2.1435937881469727,\n",
    "#     1.2315099239349365, 0.9353300929069519, 1.185146689414978,\n",
    "#     3.0140292644500732, 1.0748600959777832, 1.059897780418396,\n",
    "#     0.9168244004249573, 1.0631417036056519, 0.9659023284912109,\n",
    "#     0.518711268901825, 0.834477961063385, 1.9010533094406128,\n",
    "#     0.9566342830657959, 0.8234851360321045, 0.794682502746582,\n",
    "#     0.8382872939109802, 1.5076645612716675, 0.9902036786079407,\n",
    "#     0.5393326282501221, 0.9421656727790833, 1.3801002502441406,\n",
    "#     1.07453453540802, 0.40048131346702576, 0.956906795501709,\n",
    "#     0.6423975229263306, 1.018542766571045, 1.0093088150024414,\n",
    "#     0.9118692278862, 0.8985363841056824, 1.3286737203598022,\n",
    "#     1.3604755401611328, 0.9514925479888916, 1.0576475858688354,\n",
    "#     0.7287135124206543, 1.6342592239379883, 0.8706264495849609,\n",
    "#     0.9390481114387512, 0.848876953125, 1.3668785095214844,\n",
    "#     0.6155153512954712, 1.0189690589904785, 0.636288046836853,\n",
    "#     0.9242458343505859, 1.3248419761657715, 0.9374197125434875,\n",
    "#     1.4346919059753418, 0.8826632499694824, 1.1073352098464966,\n",
    "#     1.0529242753982544, 0.9071018099784851, 1.026792049407959,\n",
    "#     1.0727221965789795, 1.2961430549621582, 0.8728381991386414,\n",
    "#     0.8077609539031982, 1.7573695182800293, 2.2015268802642822,\n",
    "#     1.4878864288330078, 0.8190956115722656, 1.1352351903915405,\n",
    "#     0.7243146896362305, 0.8739121556282043, 1.136391043663025,\n",
    "#     1.3314666748046875, 1.277920126914978, 1.8183268308639526,\n",
    "#     1.4402602910995483, 2.3099923133850098, 0.9879258275032043,\n",
    "#     0.9845683574676514, 3.0701801776885986, 1.4820553064346313,\n",
    "#     1.0965156555175781, 0.3847064971923828, 1.183203101158142,\n",
    "#     0.9840953946113586, 1.013771653175354, 0.9816725850105286,\n",
    "#     2.1038644313812256, 1.4533437490463257, 1.2385667562484741,\n",
    "#     1.6958831548690796, 1.0946561098098755, 1.1791598796844482,\n",
    "#     1.3582277297973633, 0.6364871859550476, 1.3190068006515503,\n",
    "#     1.5198769569396973, 0.9638397097587585, 0.9200767874717712,\n",
    "#     1.426383376121521, 1.9786039590835571, 1.795615315437317,\n",
    "#     1.0502549409866333, 1.3629635572433472, 1.6785494089126587,\n",
    "#     2.4647276401519775, 1.5583362579345703, 1.7025951147079468,\n",
    "#     0.9477145075798035, 1.374899983406067, 1.3595852851867676,\n",
    "#     2.0247833728790283, 2.557070255279541, 0.8996996879577637,\n",
    "#     1.313653588294983, 0.6833868622779846, 1.1520487070083618,\n",
    "#     1.3238660097122192, 0.7916075587272644, 1.1287990808486938,\n",
    "#     0.7841978669166565, 1.4663950204849243, 1.3747987747192383,\n",
    "#     1.6817740201950073, 0.9904271960258484, 1.8169102668762207,\n",
    "#     1.0146375894546509, 1.8178905248641968, 1.157462239265442,\n",
    "#     0.930549681186676, 1.1024221181869507, 1.0701032876968384,\n",
    "#     1.6436668634414673, 0.9781878590583801, 1.621044635772705,\n",
    "#     0.9061231017112732, 0.8093452453613281, 0.49829554557800293,\n",
    "#     0.9323164820671082, 1.1232811212539673, 1.2584984302520752,\n",
    "#     2.0877320766448975, 0.3685269057750702, 1.3835235834121704,\n",
    "#     0.9161154627799988, 1.4266386032104492, 1.4028183221817017\n",
    "# ]\n",
    "\n",
    "# epochs = range(len(D_loss))\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(epochs, D_loss, label='Discriminator Loss', color='red')\n",
    "# plt.plot(epochs, G_loss, label='Generator Loss', color='blue')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('GAN Least Squared Loss Comparison Over Epochs')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_images(generator, num_images=7000, batch_size=200):\n",
    "    output_dir = \"/kaggle/working/submission2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    total_generated = 0\n",
    "    \n",
    "    for batch_start in range(0, num_images, batch_size):\n",
    "        current_batch = min(batch_size, num_images - batch_start)\n",
    "        \n",
    "        noise = tf.random.normal([current_batch, modmmgan.latent_dim])\n",
    "        generated_batch = generator(noise, training=False)\n",
    "        \n",
    "        for i in range(current_batch):\n",
    "            img = generated_batch[i]\n",
    "            img = (img + 1) * 127.5\n",
    "            img = tf.cast(tf.clip_by_value(img, 0, 255), tf.uint8)\n",
    "            \n",
    "            file_num = batch_start + i\n",
    "            file_path = os.path.join(output_dir, f\"{1 + file_num:05d}.jpg\")\n",
    "            tf.keras.utils.save_img(file_path, img, quality=95)\n",
    "        \n",
    "        total_generated += current_batch\n",
    "        \n",
    "        if total_generated % 1000 == 0:\n",
    "            remaining = (num_images - total_generated)\n",
    "            print(f\"  Generated {total_generated}/{num_images} \")\n",
    "    print(f\"âœ… Generated {total_generated} images\")\n",
    "    return output_dir\n",
    "\n",
    "images_dir = generate_submission_images(\n",
    "    generator=modmmgan.generator,\n",
    "    num_images=7100,\n",
    "    batch_size=200\n",
    ")\n",
    "\n",
    "zip_path = \"/kaggle/working/images.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Get all .jpg files sorted\n",
    "    jpg_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    for jpg_file in jpg_files:\n",
    "        file_path = os.path.join(images_dir, jpg_file)\n",
    "        zipf.write(file_path, jpg_file)\n",
    "zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "file_count = len(jpg_files)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
